{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2878313f",
   "metadata": {},
   "source": [
    "implement random forest using python\n",
    "implement ensemble learning for any three classifiers (all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0c35bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_40220\\3168386973.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Simple missing value handling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Random Forest implementation using scikit-learn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load loan approval dataset\n",
    "df = pd.read_csv('new_loan_approval_dataset.csv')  # Update with your actual file path\n",
    "\n",
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Preprocess data\n",
    "df.fillna(method='ffill', inplace=True)  # Simple missing value handling\n",
    "X = df.drop('Loan_Approved', axis=1)  # Features\n",
    "y = df['Loan_Approved']  # Target variable\n",
    "\n",
    "#Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc185fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Ensemble learning with three classifiers: Logistic Regression, Decision Tree, and SVM\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Define classifiers\n",
    "clf1 = LogisticRegression(max_iter=200)\n",
    "clf2 = DecisionTreeClassifier(random_state=42)\n",
    "clf3 = SVC(probability=True)\n",
    "\n",
    "# Ensemble using VotingClassifier\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), \n",
    "    ('dt', clf2), \n",
    "    ('svc', clf3)\n",
    "], voting='soft')\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "y_pred_ensemble = ensemble.predict(X_test)\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(y_test, y_pred_ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80cde918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy (Weak Learners + Bayes): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Ensemble learning with weak learners and Naive Bayes\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define weak learners and Bayes classifier\n",
    "clf1 = DecisionTreeClassifier(max_depth=1, random_state=42)  # Weak learner\n",
    "clf2 = KNeighborsClassifier(n_neighbors=3)                  # Weak learner\n",
    "clf3 = GaussianNB()                                         # Bayes classifier\n",
    "\n",
    "# Ensemble using VotingClassifier\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('dt', clf1),\n",
    "    ('knn', clf2),\n",
    "    ('nb', clf3)\n",
    "], voting='soft')\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "y_pred = ensemble.predict(X_test)\n",
    "print(\"Ensemble Accuracy (Weak Learners + Bayes):\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
